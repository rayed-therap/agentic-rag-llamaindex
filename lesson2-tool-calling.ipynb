{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "\n",
    "Settings.llm = Gemini(model=\"models/gemini-2.0-flash-exp\")\n",
    "Settings.embed_model = GeminiEmbedding(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define simple tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def mystery(x: int, y: int) -> int:\n",
    "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use the add tool to add 9 and 12.\n",
      "Action: add\n",
      "Action Input: {'x': 9, 'y': 12}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 21\n",
      "\u001b[0m21\n"
     ]
    }
   ],
   "source": [
    "response = Settings.llm.predict_and_call(\n",
    "    tools=[add_tool, mystery_tool], user_msg=\"Add 9 and 12.\", verbose=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use the mystery tool to find the result of the mystery function with the given inputs.\n",
      "Action: mystery\n",
      "Action Input: {'x': 45, 'y': 54}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 9801\n",
      "\u001b[0m9801\n"
     ]
    }
   ],
   "source": [
    "response = Settings.llm.predict_and_call(\n",
    "    tools=[add_tool, mystery_tool],\n",
    "    user_msg=\"What is the mystery between 45 and 54\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:fsspec.local:open file: /home/rayed/Development/agentic-rag-llamaindex/metagpt.pdf\n",
      "open file: /home/rayed/Development/agentic-rag-llamaindex/metagpt.pdf\n",
      "open file: /home/rayed/Development/agentic-rag-llamaindex/metagpt.pdf\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI...\n",
      "> Adding chunk: Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI...\n",
      "> Adding chunk: Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Figure 1: The software development SOP...\n",
      "> Adding chunk: Preprint\n",
      "Figure 1: The software development SOP...\n",
      "> Adding chunk: Preprint\n",
      "Figure 1: The software development SOP...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "• We introduce MetaGPT, a meta-program...\n",
      "> Adding chunk: Preprint\n",
      "• We introduce MetaGPT, a meta-program...\n",
      "> Adding chunk: Preprint\n",
      "• We introduce MetaGPT, a meta-program...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Other works focus on\n",
      "sociological phenomena. Fo...\n",
      "> Adding chunk: Other works focus on\n",
      "sociological phenomena. Fo...\n",
      "> Adding chunk: Other works focus on\n",
      "sociological phenomena. Fo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Figure 2: An example of the communicat...\n",
      "> Adding chunk: Preprint\n",
      "Figure 2: An example of the communicat...\n",
      "> Adding chunk: Preprint\n",
      "Figure 2: An example of the communicat...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Figure 3: A diagram showing the softwa...\n",
      "> Adding chunk: Preprint\n",
      "Figure 3: A diagram showing the softwa...\n",
      "> Adding chunk: Preprint\n",
      "Figure 3: A diagram showing the softwa...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "whispers)2, after several rounds of co...\n",
      "> Adding chunk: Preprint\n",
      "whispers)2, after several rounds of co...\n",
      "> Adding chunk: Preprint\n",
      "whispers)2, after several rounds of co...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "wareDev: (1) HumanEval includes 164 ha...\n",
      "> Adding chunk: Preprint\n",
      "wareDev: (1) HumanEval includes 164 ha...\n",
      "> Adding chunk: Preprint\n",
      "wareDev: (1) HumanEval includes 164 ha...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 4.2 M AIN RESULT\n",
      "AlphaCode(1.1B)Incoder (6.7B)C...\n",
      "> Adding chunk: 4.2 M AIN RESULT\n",
      "AlphaCode(1.1B)Incoder (6.7B)C...\n",
      "> Adding chunk: 4.2 M AIN RESULT\n",
      "AlphaCode(1.1B)Incoder (6.7B)C...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Figure 5: Demo softwares developed by ...\n",
      "> Adding chunk: Preprint\n",
      "Figure 5: Demo softwares developed by ...\n",
      "> Adding chunk: Preprint\n",
      "Figure 5: Demo softwares developed by ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Table 2: Comparison of capabilities fo...\n",
      "> Adding chunk: Preprint\n",
      "Table 2: Comparison of capabilities fo...\n",
      "> Adding chunk: Preprint\n",
      "Table 2: Comparison of capabilities fo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Acknowledgement\n",
      "We thank Sarah Salhi, ...\n",
      "> Adding chunk: Preprint\n",
      "Acknowledgement\n",
      "We thank Sarah Salhi, ...\n",
      "> Adding chunk: Preprint\n",
      "Acknowledgement\n",
      "We thank Sarah Salhi, ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Team Roles at Work. Routledge, 2012. URL https:...\n",
      "> Adding chunk: Team Roles at Work. Routledge, 2012. URL https:...\n",
      "> Adding chunk: Team Roles at Work. Routledge, 2012. URL https:...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Weize Chen, Yusheng Su, Jingwei Zuo, C...\n",
      "> Adding chunk: Preprint\n",
      "Weize Chen, Yusheng Su, Jingwei Zuo, C...\n",
      "> Adding chunk: Preprint\n",
      "Weize Chen, Yusheng Su, Jingwei Zuo, C...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Promptbreeder: Self-referential self-improvemen...\n",
      "> Adding chunk: Promptbreeder: Self-referential self-improvemen...\n",
      "> Adding chunk: Promptbreeder: Self-referential self-improvemen...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Guohao Li, Hasan Abed Al Kader Hammoud...\n",
      "> Adding chunk: Preprint\n",
      "Guohao Li, Hasan Abed Al Kader Hammoud...\n",
      "> Adding chunk: Preprint\n",
      "Guohao Li, Hasan Abed Al Kader Hammoud...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Code llama: Open foundation models for code.\n",
      "ar...\n",
      "> Adding chunk: Code llama: Open foundation models for code.\n",
      "ar...\n",
      "> Adding chunk: Code llama: Open foundation models for code.\n",
      "ar...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "J. Schmidhuber. Ultimate cognition `a ...\n",
      "> Adding chunk: Preprint\n",
      "J. Schmidhuber. Ultimate cognition `a ...\n",
      "> Adding chunk: Preprint\n",
      "J. Schmidhuber. Ultimate cognition `a ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Hongxin Zhang, Weihua Du, Jiaming Shan...\n",
      "> Adding chunk: Preprint\n",
      "Hongxin Zhang, Weihua Du, Jiaming Shan...\n",
      "> Adding chunk: Preprint\n",
      "Hongxin Zhang, Weihua Du, Jiaming Shan...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "A O UTLOOK\n",
      "A.1 S ELF -IMPROVEMENT MECH...\n",
      "> Adding chunk: Preprint\n",
      "A O UTLOOK\n",
      "A.1 S ELF -IMPROVEMENT MECH...\n",
      "> Adding chunk: Preprint\n",
      "A O UTLOOK\n",
      "A.1 S ELF -IMPROVEMENT MECH...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "and pay according to their usage. More...\n",
      "> Adding chunk: Preprint\n",
      "and pay according to their usage. More...\n",
      "> Adding chunk: Preprint\n",
      "and pay according to their usage. More...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "B A D EMO OF THE EXECUTION\n",
      "In this sec...\n",
      "> Adding chunk: Preprint\n",
      "B A D EMO OF THE EXECUTION\n",
      "In this sec...\n",
      "> Adding chunk: Preprint\n",
      "B A D EMO OF THE EXECUTION\n",
      "In this sec...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Product Requirement Document\n",
      "1\n",
      "2 ## Re...\n",
      "> Adding chunk: Preprint\n",
      "Product Requirement Document\n",
      "1\n",
      "2 ## Re...\n",
      "> Adding chunk: Preprint\n",
      "Product Requirement Document\n",
      "1\n",
      "2 ## Re...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Architect Based on the requirements in...\n",
      "> Adding chunk: Preprint\n",
      "Architect Based on the requirements in...\n",
      "> Adding chunk: Preprint\n",
      "Architect Based on the requirements in...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Figure 9: The program call flow for th...\n",
      "> Adding chunk: Preprint\n",
      "Figure 9: The program call flow for th...\n",
      "> Adding chunk: Preprint\n",
      "Figure 9: The program call flow for th...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Product Requirement Document\n",
      "1 ## Task...\n",
      "> Adding chunk: Preprint\n",
      "Product Requirement Document\n",
      "1 ## Task...\n",
      "> Adding chunk: Preprint\n",
      "Product Requirement Document\n",
      "1 ## Task...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Engineer Given the provided file struc...\n",
      "> Adding chunk: Preprint\n",
      "Engineer Given the provided file struc...\n",
      "> Adding chunk: Preprint\n",
      "Engineer Given the provided file struc...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Figure 10: The “Drawing App” generated...\n",
      "> Adding chunk: Preprint\n",
      "Figure 10: The “Drawing App” generated...\n",
      "> Adding chunk: Preprint\n",
      "Figure 10: The “Drawing App” generated...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Table 4: Executability comparison. The...\n",
      "> Adding chunk: Preprint\n",
      "Table 4: Executability comparison. The...\n",
      "> Adding chunk: Preprint\n",
      "Table 4: Executability comparison. The...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "be given a function signature and its ...\n",
      "> Adding chunk: Preprint\n",
      "be given a function signature and its ...\n",
      "> Adding chunk: Preprint\n",
      "be given a function signature and its ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Figure 11: The system interface design...\n",
      "> Adding chunk: Preprint\n",
      "Figure 11: The system interface design...\n",
      "> Adding chunk: Preprint\n",
      "Figure 11: The system interface design...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Figure 12: The program call flow for “...\n",
      "> Adding chunk: Preprint\n",
      "Figure 12: The program call flow for “...\n",
      "> Adding chunk: Preprint\n",
      "Figure 12: The program call flow for “...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Table 8: Examples of SoftwareDev datas...\n",
      "> Adding chunk: Preprint\n",
      "Table 8: Examples of SoftwareDev datas...\n",
      "> Adding chunk: Preprint\n",
      "Table 8: Examples of SoftwareDev datas...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Preprint\n",
      "Table 9: Additional results of pure Me...\n",
      "> Adding chunk: Preprint\n",
      "Table 9: Additional results of pure Me...\n",
      "> Adding chunk: Preprint\n",
      "Table 9: Additional results of pure Me...\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: metagpt.pdf\n",
      "file_path: metagpt.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16911937\n",
      "creation_date: 2024-12-29\n",
      "last_modified_date: 2024-12-29\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].get_metadata_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.indices.utils:> Top 1 nodes:\n",
      "> [Node 6b697477-ae91-490f-9dd5-c01a3b0260d3] [Similarity score:             0.69964] Preprint\n",
      "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
      "In s...\n",
      "> Top 1 nodes:\n",
      "> [Node 6b697477-ae91-490f-9dd5-c01a3b0260d3] [Similarity score:             0.69964] Preprint\n",
      "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
      "In s...\n",
      "> Top 1 nodes:\n",
      "> [Node 6b697477-ae91-490f-9dd5-c01a3b0260d3] [Similarity score:             0.69964] Preprint\n",
      "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
      "In s...\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts([{\"key\": \"page_label\", \"value\": \"2\"}]),\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What are some high-level results of MetaGPT?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaGPT achieves a new state-of-the-art with 85.9% and 87.7% in Pass@1 in code generation benchmarks. It also achieves a 100% task completion rate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-12-29', 'last_modified_date': '2024-12-29'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define auto-retrieval tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "\n",
    "\n",
    "def vector_query(query: str, page_numbers: List[str]) -> str:\n",
    "    \"\"\"Perform a vector search over an index.\n",
    "\n",
    "    Args:\n",
    "        query: The query to search for.\n",
    "        page_numbers: The page numbers to filter the search. If empty, search over all pages.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    metadata_dicts = [{\"key\": \"page_label\", \"value\": page} for page in page_numbers]\n",
    "    filters = MetadataFilters.from_dicts(metadata_dicts, condition=FilterCondition.OR)\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k=2, filters=filters)\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMetadata(description='vector_tool(query: str, page_numbers: List[str]) -> str\\nPerform a vector search over an index.\\n\\n    Args:\\n        query: The query to search for.\\n        page_numbers: The page numbers to filter the search. If empty, search over all pages.\\n\\n    ', name='vector_tool', fn_schema=<class 'llama_index.core.tools.utils.vector_tool'>, return_direct=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_query_tool = FunctionTool.from_defaults(name=\"vector_tool\", fn=vector_query)\n",
    "vector_query_tool.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: vector_tool\n",
      "Action Input: {'query': 'high-level results of MetaGPT', 'page_numbers': []}\n",
      "\u001b[0mDEBUG:llama_index.core.indices.utils:> Top 2 nodes:\n",
      "> [Node c5d22293-fd51-40c3-a279-58c9082757b2] [Similarity score:             0.720623] 4.2 M AIN RESULT\n",
      "AlphaCode(1.1B)Incoder (6.7B)CodeGeeX (13B)\n",
      "17.1 \n",
      "— \n",
      "15.2 17.6 18.9 26.9 \n",
      "CodeGe...\n",
      "> [Node 64d931f6-225b-4325-a75c-35e7c1d1bbd8] [Similarity score:             0.714395] Preprint\n",
      "Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tian...\n",
      "> Top 2 nodes:\n",
      "> [Node c5d22293-fd51-40c3-a279-58c9082757b2] [Similarity score:             0.720623] 4.2 M AIN RESULT\n",
      "AlphaCode(1.1B)Incoder (6.7B)CodeGeeX (13B)\n",
      "17.1 \n",
      "— \n",
      "15.2 17.6 18.9 26.9 \n",
      "CodeGe...\n",
      "> [Node 64d931f6-225b-4325-a75c-35e7c1d1bbd8] [Similarity score:             0.714395] Preprint\n",
      "Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tian...\n",
      "> Top 2 nodes:\n",
      "> [Node c5d22293-fd51-40c3-a279-58c9082757b2] [Similarity score:             0.720623] 4.2 M AIN RESULT\n",
      "AlphaCode(1.1B)Incoder (6.7B)CodeGeeX (13B)\n",
      "17.1 \n",
      "— \n",
      "15.2 17.6 18.9 26.9 \n",
      "CodeGe...\n",
      "> [Node 64d931f6-225b-4325-a75c-35e7c1d1bbd8] [Similarity score:             0.714395] Preprint\n",
      "Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tian...\n",
      "\u001b[1;3;34mObservation: MetaGPT achieves pass rates of 85.9% and 87.7% on the HumanEval and MBPP benchmarks, respectively. It also outperforms all previous methods in both benchmarks.\n",
      "\n",
      "\u001b[0mMetaGPT achieves pass rates of 85.9% and 87.7% on the HumanEval and MBPP benchmarks, respectively. It also outperforms all previous methods in both benchmarks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = Settings.llm.predict_and_call(\n",
    "    tools=[vector_query_tool],\n",
    "    user_msg=\"What are the high-level results of MetaGPT?\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '7', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-12-29', 'last_modified_date': '2024-12-29'}\n",
      "{'page_label': '14', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-12-29', 'last_modified_date': '2024-12-29'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add other tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.tools.function_tool.FunctionTool"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vector_query_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    reponse_mode=\"tree_summarize\", use_async=True\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=\"Useful for a summary of MetaGPT.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.tools.query_engine.QueryEngineTool"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(summary_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use the vector_tool to find the comparisons between MetaGPT and ChatDev on page 8.\n",
      "Action: vector_tool\n",
      "Action Input: {'query': 'MetaGPT comparisons with ChatDev', 'page_numbers': ['8']}\n",
      "\u001b[0mDEBUG:llama_index.core.indices.utils:> Top 1 nodes:\n",
      "> [Node 807bb05b-72d5-4325-ac99-caeac9a36c60] [Similarity score:             0.727834] Preprint\n",
      "Figure 5: Demo softwares developed by MetaGPT.\n",
      "in these two public benchmarks. Moreover,...\n",
      "> Top 1 nodes:\n",
      "> [Node 807bb05b-72d5-4325-ac99-caeac9a36c60] [Similarity score:             0.727834] Preprint\n",
      "Figure 5: Demo softwares developed by MetaGPT.\n",
      "in these two public benchmarks. Moreover,...\n",
      "> Top 1 nodes:\n",
      "> [Node 807bb05b-72d5-4325-ac99-caeac9a36c60] [Similarity score:             0.727834] Preprint\n",
      "Figure 5: Demo softwares developed by MetaGPT.\n",
      "in these two public benchmarks. Moreover,...\n",
      "\u001b[1;3;34mObservation: MetaGPT outperforms ChatDev on the SoftwareDev dataset in nearly all metrics. It achieves a higher executability score, takes less time, and has a lower human revision cost. While MetaGPT uses more tokens overall, it requires fewer tokens to generate one line of code compared to ChatDev.\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = Settings.llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"What are the MetaGPT comparisons with ChatDev described on page 8?\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-12-29', 'last_modified_date': '2024-12-29'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: summary_tool\n",
      "Action Input: {'input': 'What is a summary of the paper?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: This paper introduces MetaGPT, a meta-programming framework for multi-agent collaboration using large language models. It incorporates human workflows into the system by encoding Standardized Operating Procedures (SOPs) into prompt sequences. This allows agents with domain expertise to verify intermediate results and reduce errors. MetaGPT uses an assembly line paradigm to assign diverse roles to various agents, breaking down complex tasks into subtasks. The framework achieves state-of-the-art performance on code generation benchmarks and demonstrates robustness and efficiency in software engineering tasks.\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = Settings.llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \"What is a summary of the paper?\", \n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-rag-llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
